{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548aaa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (2500, 4500)\n",
      "test data:  (500, 4500)\n"
     ]
    }
   ],
   "source": [
    "########## PROJECT: support vector machine ###############\n",
    "\n",
    "'''We will be predicting the sentiment (positive or negative) of a single sentence taken from a review of a movie, \n",
    "restaurant, or product. The data set consists of 3000 labeled sentences, which we divide into a training set of size \n",
    "2500 and a test set of size 500. We have already used a logistic regression classifier. Now, we will use a support \n",
    "vector machine.'''\n",
    "\n",
    "import string \n",
    "import numpy as np \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn import svm \n",
    "#Loading and preprocessing the data \n",
    "#Read in the data set: \n",
    "with open(\"data/full_set.txt\") as f: \n",
    "    content = f.readlines() \n",
    "#Remove leading and trailing white space: \n",
    "content = [x.strip() for x in content] \n",
    "#Separate the sentences from the labels: \n",
    "sentences = [x.split(\"\\t\")[0] for x in content] \n",
    "labels = [x.split(\"\\t\")[1] for x in content] \n",
    "#Transform the labels from '0 versus 1' to '-1 versus 1':\n",
    "y = np.array(labels, dtype='int8') \n",
    "y = 2*y - 1 \n",
    "#Let us define a function, \"full_remove\" that takes a string x \n",
    "# and a list of characters from a removal_list and returns with all the \n",
    "# characters in removal_list replaced by ' '. \n",
    "def full_remove(x, removal_list): \n",
    "    for w in removal_list: \n",
    "        x = x.replace(w, ' ') \n",
    "    return x \n",
    "#Remove digits: \n",
    "digits = [str(x) for x in range(10)] \n",
    "digit_less = [full_remove(x, digits) for x in sentences] \n",
    "#Remove punctuation: \n",
    "punc_less = [full_remove(x, list(string.punctuation)) for x in digit_less] \n",
    "#Make everything lower-case: \n",
    "sents_lower = [x.lower() for x in punc_less] \n",
    "#Define our stop words: \n",
    "stop_set = set(['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from']) \n",
    "#Remove stop words \n",
    "sents_split = [x.split() for x in sents_lower] \n",
    "sents_processed = [\" \".join(list(filter(lambda a: a not in stop_set, x))) for x in sents_split] \n",
    "#Transform to bag of words representation: \n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, \n",
    "                             stop_words = None, max_features = 4500) \n",
    "data_features = vectorizer.fit_transform(sents_processed) \n",
    "#Append '1' to the end of each vector. \n",
    "data_mat = data_features.toarray() \n",
    "#Split the data into testing and training sets: \n",
    "np.random.seed(0) \n",
    "test_inds = np.append(np.random.choice((np.where(y==-1))[0], 250, replace=False),\n",
    "                      np.random.choice((np.where(y==1))[0], 250, replace=False)) \n",
    "train_inds = list(set(range(len(labels))) - set(test_inds)) \n",
    "train_data = data_mat[train_inds,] \n",
    "train_labels = y[train_inds] \n",
    "test_data = data_mat[test_inds,] \n",
    "test_labels = y[test_inds] \n",
    "print(\"train data: \", train_data.shape) \n",
    "print(\"test data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32083006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 0.01: train 0.215 test 0.250\n",
      "Error rate for C = 0.10: train 0.074 test 0.174\n",
      "Error rate for C = 1.00: train 0.011 test 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 10.00: train 0.002 test 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 100.00: train 0.002 test 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 1000.00: train 0.003 test 0.206\n",
      "Error rate for C = 10000.00: train 0.001 test 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "'''Fitting a support vector machine to the data\n",
    "In support vector machines, we are given a set of examples ( 1, 1),…,( , ) and we want \n",
    "to find a weight vector ∈ℝ that solves the following optimization problem:\n",
    "scikit-learn provides an SVM solver that we will use. The following routine \n",
    "takes the constant \"C\" as an input (from the above optimization problem) and returns \n",
    "the training and test error of the resulting SVM model. It is invoked as follows:\n",
    " \"training_error, test_error = fit_classifier(C)\"\n",
    " The default value for parameter \"C\" is 1.0.'''\n",
    "\n",
    "#Fitting a support vector machine to the data \n",
    "def fit_classifier(C_value=1.0): \n",
    "    clf = svm.LinearSVC(C=C_value, loss='hinge') \n",
    "    clf.fit(train_data,train_labels) \n",
    "    # Get predictions on training data \n",
    "    train_preds = clf.predict(train_data) \n",
    "    train_error = float(np.sum((train_preds > 0.0) != (train_labels > 0.0)))/len(train_labels) \n",
    "    # Get predictions on test data \n",
    "    test_preds = clf.predict(test_data) \n",
    "    test_error = float(np.sum((test_preds > 0.0) != (test_labels > 0.0)))/len(test_labels) \n",
    "    return train_error, test_error \n",
    "cvals = [0.01,0.1,1.0,10.0,100.0,1000.0,10000.0] \n",
    "for c in cvals: \n",
    "    train_error, test_error = fit_classifier(c) \n",
    "    print (\"Error rate for C = %0.2f: train %0.3f test %0.3f\" % (c, train_error, test_error)) \n",
    "#We see that the minimum test error is for C = 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a65bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2241793434747798\n",
      "cross_validation_error: \n",
      "0.2070448371656355\n",
      "cross_validation_error: \n",
      "0.19951923076923078\n",
      "cross_validation_error: \n",
      "0.18917835671342684\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2016846231078159\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1957445899708198\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19259239220051116\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18426521797264223\n"
     ]
    }
   ],
   "source": [
    "'''3. Evaluating C by k-fold cross-validation\n",
    " As we can see, the choice of \"C\" has a very significant effect on the performance of the SVM classifier. We were able to assess this because we have a separate test set. In general, however, this is a luxury we won't possess.\n",
    " A reasonable way to estimate the error associated with a specific value of \"C\" is by k-fold cross validation:\n",
    "o Partition the training set into \"k\" equal-sized sized subsets.\n",
    "o For i=1,2,...,k, train a classifier with parameter C.. Average the errors: \"(e_1 + ... + e_k)/k\"\n",
    " The following procedure, cross_validation_error, does exactly this. It takes as input:\n",
    "o the training set \"x,y\"\n",
    "o the value of \"C\" to be evaluated\n",
    "o the integer \"k\"\n",
    " It returns the estimated error of the classifier for that particular setting of \"C\".'''\n",
    "\n",
    "\n",
    "#3. Evaluating C by k-fold cross-validation \n",
    "def cross_validation_error(x,y,C_value,k): \n",
    "    n = len(y) \n",
    "    # Randomly shuffle indices \n",
    "    indices = np.random.permutation(n) \n",
    "    # Initialize error \n",
    "    err = 0.0 \n",
    "    # Iterate over partitions \n",
    "    for i in range(k): \n",
    "        # Partition indices \n",
    "        test_indices = indices[int(i*(n/k)):int((i+1)*(n/k) - 1)] \n",
    "        train_indices = np.setdiff1d(indices, test_indices) \n",
    "        # Train classifier with parameter c \n",
    "        clf = svm.LinearSVC(C=C_value, loss='hinge') \n",
    "        clf.fit(x[train_indices], y[train_indices]) \n",
    "        # Get predictions on test partition \n",
    "        preds = clf.predict(x[test_indices]) \n",
    "        # Compute error \n",
    "        err += float(np.sum((preds > 0.0) != (y[test_indices] > 0.0)))/len(test_indices) \n",
    "    return err/k \n",
    "    #Let us print out the eoees or ifferen vaues of k \n",
    "for k in range(2,10): \n",
    "    print(\"cross_validation_error: \") \n",
    "    print(cross_validation_error(train_data,train_labels,1.0,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c8253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de689a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
